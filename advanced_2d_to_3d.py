import numpy as np
import cv2
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.cluster import DBSCAN
from scipy import ndimage
from scipy.spatial import KDTree
import torch
import torch.nn as nn
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import threading
from queue import Queue
import time
import os

class NeuralDepthEstimator(nn.Module):
    def __init__(self):
        super(NeuralDepthEstimator, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.deconv1 = nn.ConvTranspose2d(128, 64, 3, padding=1)
        self.deconv2 = nn.ConvTranspose2d(64, 32, 3, padding=1)
        self.deconv3 = nn.ConvTranspose2d(32, 1, 3, padding=1)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.relu(self.conv3(x))
        x = self.relu(self.deconv1(x))
        x = self.relu(self.deconv2(x))
        x = self.sigmoid(self.deconv3(x))
        return x

class FuzzySphericalTransformer:
    def __init__(self):
        self.membership_cache = {}
    
    def cartesian_to_spherical(self, x, y, z):
        r = np.sqrt(x**2 + y**2 + z**2)
        if r == 0:
            return 0, 0, 0
        theta = np.arccos(z / r)
        phi = np.arctan2(y, x)
        return r, theta, phi
    
    def calculate_pixel_membership(self, x, y, image):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±Ø¬Ù‡ Ø¹Ø¶ÙˆÛŒØª ÙØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒÚ©Ø³Ù„"""
        intensity = image[y, x] if len(image.shape) == 2 else np.mean(image[y, x])
        
        # ØªØ§Ø¨Ø¹ Ø¹Ø¶ÙˆÛŒØª ÙØ§Ø²ÛŒ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡
        intensity_membership = 1.0 - abs(intensity - 0.5) / 0.5
        
        return intensity_membership
    
    def fuzzy_cartesian_to_spherical(self, x, y, image, center_x, center_y):
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ø®ØªØµØ§Øª
        norm_x = (x - center_x) / max(center_x, 1)
        norm_y = (y - center_y) / max(center_y, 1)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±Ø¬Ù‡ Ø¹Ø¶ÙˆÛŒØª
        membership = self.calculate_pixel_membership(x, y, image)
        
        # Ø§Ø¹Ù…Ø§Ù„ Ù…Ù†Ø·Ù‚ ÙØ§Ø²ÛŒ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„
        fuzzy_r = np.sqrt(norm_x**2 + norm_y**2) * (0.3 + 0.7 * membership)
        fuzzy_theta = np.arctan2(norm_y, norm_x)
        fuzzy_phi = (np.pi / 2) * membership  # Ø²Ø§ÙˆÛŒÙ‡ Ø§Ø±ØªÙØ§Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ø¶ÙˆÛŒØª
        
        return fuzzy_r, fuzzy_theta, fuzzy_phi, membership

class Advanced2DTo3DConverter:
    def __init__(self):
        self.fuzzy_transformer = FuzzySphericalTransformer()
        self.depth_estimator = self.load_depth_estimator()
        self.progress_queue = Queue()
        
    def load_depth_estimator(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªØ®Ù…ÛŒÙ† Ø¹Ù…Ù‚"""
        try:
            model = NeuralDepthEstimator()
            # Ø­Ø§Ù„Øª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
            model.eval()
            return model
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")
            return None
    
    def load_and_preprocess_image(self, image_path):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±"""
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError("Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø±Ø¯")
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø®Ø§Ú©Ø³ØªØ±ÛŒ
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            
            # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
            h, w = gray.shape
            max_dim = 400  # Ø­Ø¯Ø§Ú©Ø«Ø± Ø¨Ø¹Ø¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹â€ŒØªØ±
            if max(h, w) > max_dim:
                scale = max_dim / max(h, w)
                new_w = int(w * scale)
                new_h = int(h * scale)
                gray = cv2.resize(gray, (new_w, new_h))
            
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            normalized = gray.astype(np.float32) / 255.0
            
            self.progress_queue.put("ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯")
            return normalized, gray
            
        except Exception as e:
            self.progress_queue.put(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±: {str(e)}")
            return None, None
    
    def estimate_depth_map(self, image):
        """ØªØ®Ù…ÛŒÙ† Ù†Ù‚Ø´Ù‡ Ø¹Ù…Ù‚"""
        try:
            if self.depth_estimator is not None and torch.cuda.is_available():
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¹ØµØ¨ÛŒ
                input_tensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).float()
                with torch.no_grad():
                    depth = self.depth_estimator(input_tensor)
                depth_map = depth.squeeze().numpy()
            else:
                # Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†
                depth_map = self.gradient_based_depth(image)
            
            self.progress_queue.put("Ù†Ù‚Ø´Ù‡ Ø¹Ù…Ù‚ ØªØ®Ù…ÛŒÙ† Ø²Ø¯Ù‡ Ø´Ø¯")
            return depth_map
            
        except Exception as e:
            self.progress_queue.put(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ®Ù…ÛŒÙ† Ø¹Ù…Ù‚: {str(e)}")
            return self.gradient_based_depth(image)
    
    def gradient_based_depth(self, image):
        """ØªØ®Ù…ÛŒÙ† Ø¹Ù…Ù‚ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†"""
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù…Ø¹Ú©ÙˆØ³ Ú©Ø±Ø¯Ù† (Ù…Ù†Ø§Ø·Ù‚ Ø¨Ø§ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¨Ø§Ù„Ø§ = Ø¹Ù…Ù‚ Ú©Ù…ØªØ±)
        if np.max(gradient_magnitude) > 0:
            depth = 1.0 - (gradient_magnitude / np.max(gradient_magnitude))
        else:
            depth = np.ones_like(image)
        return depth
    
    def convert_to_3d_points(self, image, depth_map):
        """ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ± 2D Ø¨Ù‡ Ù†Ù‚Ø§Ø· 3D"""
        try:
            h, w = image.shape
            center_x, center_y = w // 2, h // 2
            
            points_3d = []
            colors = []
            
            # Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
            step = max(1, min(h, w) // 100)  # Ø§ÙØ²Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ØªØ±
            
            total_pixels = (h // step) * (w // step)
            processed = 0
            
            for y in range(0, h, step):
                for x in range(0, w, step):
                    if image[y, x] > 0.05:  # Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± ØªØ§Ø±ÛŒÚ©
                        # ØªØ¨Ø¯ÛŒÙ„ ÙØ§Ø²ÛŒ-Ú©Ø±ÙˆÛŒ
                        r, theta, phi, membership = self.fuzzy_transformer.fuzzy_cartesian_to_spherical(
                            x, y, image, center_x, center_y
                        )
                        
                        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¹Ù…Ù‚ ØªØ®Ù…ÛŒÙ†â€ŒØ²Ø¯Ù‡ Ø´Ø¯Ù‡
                        depth_val = depth_map[y, x] if depth_map is not None else membership
                        
                        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª Ú©Ø§Ø±ØªØ²ÛŒÙ† 3D
                        scale_factor = min(h, w) / 4  # ÙØ§Ú©ØªÙˆØ± Ù…Ù‚ÛŒØ§Ø³ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±
                        x_3d = r * np.cos(theta) * np.sin(phi) * depth_val * scale_factor
                        y_3d = r * np.sin(theta) * np.sin(phi) * depth_val * scale_factor
                        z_3d = r * np.cos(phi) * depth_val * scale_factor * 2
                        
                        points_3d.append([x_3d, y_3d, z_3d])
                        
                        # Ø±Ù†Ú¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø¯Øª ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ
                        intensity = int(image[y, x] * 255)
                        colors.append([intensity, intensity, intensity])
                    
                    processed += 1
                    if processed % 1000 == 0:
                        progress = (processed / total_pixels) * 100
                        self.progress_queue.put(f"ØªØ¨Ø¯ÛŒÙ„ 3D: {progress:.1f}%")
            
            points_3d = np.array(points_3d)
            colors = np.array(colors)
            
            self.progress_queue.put(f"ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‚Ø§Ø· 3D ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡: {len(points_3d)}")
            return points_3d, colors, None
            
        except Exception as e:
            self.progress_queue.put(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ 3D: {str(e)}")
            return None, None, None
    
    def apply_spatial_corrections(self, points_3d, colors, valid_indices=None):
        """Ø§Ø¹Ù…Ø§Ù„ ØªØµØ­ÛŒØ­Ø§Øª ÙØ¶Ø§ÛŒÛŒ"""
        try:
            if len(points_3d) < 10:
                return points_3d, colors
            
            # 1. Ø­Ø°Ù Ù†Ù‚Ø§Ø· Ù¾Ø±Øª Ø¨Ø§ DBSCAN (Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡)
            if len(points_3d) > 50:
                try:
                    clustering = DBSCAN(eps=0.5, min_samples=5).fit(points_3d)
                    labels = clustering.labels_
                    
                    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ù†Ù‚Ø§Ø·ÛŒ Ú©Ù‡ Ù†ÙˆÛŒØ² Ù†ÛŒØ³ØªÙ†Ø¯ (label != -1)
                    if np.sum(labels != -1) > 10:
                        points_3d = points_3d[labels != -1]
                        colors = colors[labels != -1]
                except:
                    pass  # Ø§Ú¯Ø± DBSCAN Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡
            
            # 2. Ù‡Ù…ÙˆØ§Ø±Ø³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡
            if len(points_3d) > 3:
                for i in range(3):
                    points_3d[:, i] = ndimage.gaussian_filter1d(points_3d[:, i], sigma=0.5)
            
            self.progress_queue.put("ØªØµØ­ÛŒØ­Ø§Øª ÙØ¶Ø§ÛŒÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯")
            return points_3d, colors
            
        except Exception as e:
            self.progress_queue.put(f"Ø®Ø·Ø§ Ø¯Ø± ØªØµØ­ÛŒØ­Ø§Øª ÙØ¶Ø§ÛŒÛŒ: {str(e)}")
            return points_3d, colors

class ThreeDViewer:
    def __init__(self, root):
        self.root = root
        self.root.title("Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªØ¨Ø¯ÛŒÙ„ 2D Ø¨Ù‡ 3D - Persian AI")
        self.root.geometry("1000x700")
        
        self.converter = Advanced2DTo3DConverter()
        self.current_points = None
        self.current_colors = None
        
        self.setup_ui()
        self.check_progress_queue()
    
    def setup_ui(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ"""
        # ÙØ±ÛŒÙ… Ø§ØµÙ„ÛŒ
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # ÙØ±ÛŒÙ… Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=5)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        ttk.Button(control_frame, text="ğŸ“ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±", 
                  command=self.load_image).pack(side=tk.LEFT, padx=5)
        ttk.Button(control_frame, text="ğŸ”„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D", 
                  command=self.start_conversion).pack(side=tk.LEFT, padx=5)
        ttk.Button(control_frame, text="ğŸ‘ï¸ Ù†Ù…Ø§ÛŒØ´ 3D", 
                  command=self.show_3d).pack(side=tk.LEFT, padx=5)
        ttk.Button(control_frame, text="ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„", 
                  command=self.save_model).pack(side=tk.LEFT, padx=5)
        
        # Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
        self.progress = ttk.Progressbar(control_frame, mode='indeterminate')
        self.progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)
        
        # ÙˆØ¶Ø¹ÛŒØª
        self.status_var = tk.StringVar(value="Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±")
        status_label = ttk.Label(control_frame, textvariable=self.status_var, 
                                font=('Tahoma', 10))
        status_label.pack(side=tk.RIGHT, padx=5)
        
        # ÙØ±ÛŒÙ… Ù†Ù…Ø§ÛŒØ´
        display_frame = ttk.Frame(main_frame)
        display_frame.pack(fill=tk.BOTH, expand=True)
        
        # Ù†Ù…ÙˆØ¯Ø§Ø±
        self.fig = plt.Figure(figsize=(8, 6), dpi=100)
        self.canvas = FigureCanvasTkAgg(self.fig, display_frame)
        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # Ú©Ù†Ø³ÙˆÙ„ log
        log_frame = ttk.LabelFrame(main_frame, text="Ù„Ø§Ú¯ Ø¹Ù…Ù„ÛŒØ§Øª")
        log_frame.pack(fill=tk.X, pady=5)
        
        self.log_text = tk.Text(log_frame, height=4, width=80, font=('Tahoma', 9))
        scrollbar = ttk.Scrollbar(log_frame, command=self.log_text.yview)
        self.log_text.config(yscrollcommand=scrollbar.set)
        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
    
    def log_message(self, message):
        """Ø§ÙØ²ÙˆØ¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ù„Ø§Ú¯"""
        self.log_text.insert(tk.END, f"{time.strftime('%H:%M:%S')} - {message}\n")
        self.log_text.see(tk.END)
        self.root.update_idletasks()
    
    def load_image(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±"""
        file_path = filedialog.askopenfilename(
            title="Ø§Ù†ØªØ®Ø§Ø¨ ØªØµÙˆÛŒØ±",
            filetypes=[("ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±ÛŒ", "*.jpg *.jpeg *.png *.bmp *.tiff"), ("Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§", "*.*")]
        )
        
        if file_path:
            self.status_var.set("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±...")
            self.progress.start()
            self.log_message(f"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±: {os.path.basename(file_path)}")
            
            # Ø§Ø¬Ø±Ø§ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            thread = threading.Thread(target=self._load_image_thread, args=(file_path,))
            thread.daemon = True
            thread.start()
    
    def _load_image_thread(self, file_path):
        """Thread Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±"""
        try:
            self.original_image, self.gray_image = self.converter.load_and_preprocess_image(file_path)
            
            if self.original_image is not None:
                self.root.after(0, lambda: self._on_image_loaded())
            else:
                self.root.after(0, lambda: self._on_image_load_failed())
                
        except Exception as e:
            self.root.after(0, lambda: self._on_image_load_error(str(e)))
    
    def _on_image_loaded(self):
        """ÙˆÙ‚ØªÛŒ ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯"""
        self.status_var.set("ØªØµÙˆÛŒØ± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ - Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D")
        self.progress.stop()
        self.show_original_image()
        self.log_message("ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯")
    
    def _on_image_load_failed(self):
        """ÙˆÙ‚ØªÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ± Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯"""
        self.status_var.set("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±")
        self.progress.stop()
        messagebox.showerror("Ø®Ø·Ø§", "Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø±Ø¯")
    
    def _on_image_load_error(self, error_msg):
        """ÙˆÙ‚ØªÛŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ± Ø±Ø® Ø¯Ø§Ø¯"""
        self.status_var.set("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ")
        self.progress.stop()
        messagebox.showerror("Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±: {error_msg}")
    
    def show_original_image(self):
        """Ù†Ù…Ø§ÛŒØ´ ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ"""
        self.fig.clear()
        ax = self.fig.add_subplot(111)
        if hasattr(self, 'gray_image'):
            ax.imshow(self.gray_image, cmap='gray')
        ax.set_title('ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ (Ø®Ø§Ú©Ø³ØªØ±ÛŒ)')
        ax.axis('off')
        self.canvas.draw()
    
    def start_conversion(self):
        """Ø´Ø±ÙˆØ¹ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D"""
        if not hasattr(self, 'gray_image'):
            messagebox.showerror("Ø®Ø·Ø§", "Ù„Ø·ÙØ§ Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© ØªØµÙˆÛŒØ± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯")
            return
        
        self.status_var.set("Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D... Ù„Ø·ÙØ§ ØµØ¨Ø± Ú©Ù†ÛŒØ¯")
        self.progress.start()
        self.log_message("Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªØ¨Ø¯ÛŒÙ„ 2D Ø¨Ù‡ 3D...")
        
        # Ø§Ø¬Ø±Ø§ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        thread = threading.Thread(target=self._conversion_thread)
        thread.daemon = True
        thread.start()
    
    def _conversion_thread(self):
        """Thread Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ 3D"""
        try:
            # 1. ØªØ®Ù…ÛŒÙ† Ø¹Ù…Ù‚
            self.converter.progress_queue.put("Ø¯Ø± Ø­Ø§Ù„ ØªØ®Ù…ÛŒÙ† Ù†Ù‚Ø´Ù‡ Ø¹Ù…Ù‚...")
            depth_map = self.converter.estimate_depth_map(self.gray_image)
            
            # 2. ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù†Ù‚Ø§Ø· 3D
            self.converter.progress_queue.put("Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù†Ù‚Ø§Ø· 3D...")
            points_3d, colors, valid_indices = self.converter.convert_to_3d_points(
                self.gray_image, depth_map
            )
            
            if points_3d is not None and len(points_3d) > 0:
                # 3. Ø§Ø¹Ù…Ø§Ù„ ØªØµØ­ÛŒØ­Ø§Øª
                self.converter.progress_queue.put("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ ØªØµØ­ÛŒØ­Ø§Øª ÙØ¶Ø§ÛŒÛŒ...")
                points_3d, colors = self.converter.apply_spatial_corrections(
                    points_3d, colors, valid_indices
                )
                
                self.current_points = points_3d
                self.current_colors = colors
                
                self.root.after(0, lambda: self._on_conversion_success())
            else:
                self.root.after(0, lambda: self._on_conversion_failed())
                
        except Exception as e:
            self.root.after(0, lambda: self._on_conversion_error(str(e)))
    
    def _on_conversion_success(self):
        """ÙˆÙ‚ØªÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯"""
        self.status_var.set("ØªØ¨Ø¯ÛŒÙ„ 3D Ú©Ø§Ù…Ù„ Ø´Ø¯ - Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´")
        self.progress.stop()
        self.log_message("ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
        messagebox.showinfo("Ù…ÙˆÙÙ‚", "ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!\nØ§Ú©Ù†ÙˆÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¯Ù„ Ø±Ø§ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
    
    def _on_conversion_failed(self):
        """ÙˆÙ‚ØªÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯"""
        self.status_var.set("Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ 3D")
        self.progress.stop()
        messagebox.showerror("Ø®Ø·Ø§", "ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯. Ù„Ø·ÙØ§ ØªØµÙˆÛŒØ± Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯.")
    
    def _on_conversion_error(self, error_msg):
        """ÙˆÙ‚ØªÛŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø±Ø® Ø¯Ø§Ø¯"""
        self.status_var.set("Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„")
        self.progress.stop()
        messagebox.showerror("Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D: {error_msg}")
    
    def check_progress_queue(self):
        """Ø¨Ø±Ø±Ø³ÛŒ ØµÙ Ù¾ÛŒØ´Ø±ÙØª"""
        try:
            while True:
                message = self.converter.progress_queue.get_nowait()
                self.log_message(message)
        except:
            pass
        
        # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯
        self.root.after(100, self.check_progress_queue)
    
    def show_3d(self):
        """Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„ 3D"""
        if self.current_points is None or len(self.current_points) == 0:
            messagebox.showerror("Ø®Ø·Ø§", "Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ 3D Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        
        self.fig.clear()
        ax = self.fig.add_subplot(111, projection='3d')
        
        # Ù†Ù…Ø§ÛŒØ´ Ø§Ø¨Ø± Ù†Ù‚Ø§Ø·
        scatter = ax.scatter(
            self.current_points[:, 0],
            self.current_points[:, 1], 
            self.current_points[:, 2],
            c=self.current_colors[:, 0] / 255.0,
            cmap='viridis',
            s=20,
            alpha=0.7,
            depthshade=True
        )
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…ÙˆØ¯Ø§Ø±
        ax.set_xlabel('Ù…Ø­ÙˆØ± X')
        ax.set_ylabel('Ù…Ø­ÙˆØ± Y')
        ax.set_zlabel('Ù…Ø­ÙˆØ± Z')
        ax.set_title(f'Ù…Ø¯Ù„ Ø³Ù‡ Ø¨Ø¹Ø¯ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ - {len(self.current_points)} Ù†Ù‚Ø·Ù‡')
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† colorbar
        plt.colorbar(scatter, ax=ax, shrink=0.5, aspect=20, label='Ø´Ø¯Øª')
        
        self.canvas.draw()
        self.log_message("Ù…Ø¯Ù„ 3D Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯")
        self.status_var.set("Ù…Ø¯Ù„ 3D Ø¯Ø± Ø­Ø§Ù„ Ù†Ù…Ø§ÛŒØ´")
    
    def save_model(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ 3D"""
        if self.current_points is None:
            messagebox.showerror("Ø®Ø·Ø§", "Ù‡ÛŒÚ† Ù…Ø¯Ù„ 3D Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ 3D",
            defaultextension=".npy",
            filetypes=[("ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ NPY", "*.npy"), ("Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§", "*.*")]
        )
        
        if file_path:
            try:
                # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø§Ø· Ùˆ Ø±Ù†Ú¯â€ŒÙ‡Ø§
                model_data = {
                    'points': self.current_points,
                    'colors': self.current_colors
                }
                np.save(file_path, model_data)
                
                self.log_message(f"Ù…Ø¯Ù„ 3D Ø¯Ø± {file_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
                messagebox.showinfo("Ù…ÙˆÙÙ‚", f"Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!\nØªØ¹Ø¯Ø§Ø¯ Ù†Ù‚Ø§Ø·: {len(self.current_points)}")
                
            except Exception as e:
                messagebox.showerror("Ø®Ø·Ø§", f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„: {str(e)}")

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    try:
        root = tk.Tk()
        app = ThreeDViewer(root)
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø®ÙˆØ´Ø§Ù…Ø¯
        app.log_message("=== Ø³ÛŒØ³ØªÙ… ØªØ¨Ø¯ÛŒÙ„ 2D Ø¨Ù‡ 3D Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯ ===")
        app.log_message("Ù„Ø·ÙØ§ ÛŒÚ© ØªØµÙˆÛŒØ± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ø³Ù¾Ø³ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3D Ø±Ø§ Ø¢ØºØ§Ø² Ú©Ù†ÛŒØ¯")
        
        root.mainloop()
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡: {e}")
        messagebox.showerror("Ø®Ø·Ø§ÛŒ Ø³ÛŒØ³ØªÙ…ÛŒ", f"Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯: {e}")

if __name__ == "__main__":
    main()
